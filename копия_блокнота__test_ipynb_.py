# -*- coding: utf-8 -*-
"""Копия блокнота "test.ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jcp8ZL2KVm5_Wyq4feFRIAdd94scSMux

Тестовое задание: https://docs.google.com/document/d/1fBOIFlrK46Gcux_d1BeAi9Bd-0g7klobTRPst0CZUOM/edit?usp=sharing
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import  files
import numpy as np
import os
# %matplotlib inline
from google.colab import drive
from PIL import Image
from tensorflow.keras.preprocessing import  image
import time, random
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, Conv2D, Input, concatenate, Activation, MaxPooling2D, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator
from glob import glob

drive.mount('/content/drive')

!unzip -q '/content/drive/MyDrive/text_cleaning.zip' -d /content/text_cleaning

images_dir = '/content/text_cleaning/text_cleaning/train_Y'               
IMG_HEIGHT = 420
IMG_WIDTH = 540

def load_images(images_dir,IMG_HEIGHT , IMG_WIDTH): 
  list_images = [] 
  for img in os.listdir(images_dir): 
    list_images.append(image.img_to_array(image.load_img(os.path.join(images_dir, img), target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='grayscale')))
  return np.array(list_images)

cur_time = time.time() 
xTrain_imag = load_images(images_dir, IMG_HEIGHT, IMG_WIDTH) 
print ('Время загрузки: ', round(time.time()-cur_time, 2), 'с', sep='')

xTrain_img = xTrain_imag/255

xTrain_img.shape

plt.imshow(xTrain_img[np.random.randint(0, xTrain_img.shape[0])].reshape(420, 540), cmap='gray') 
plt.show()

X_images_dir = '/content/text_cleaning/text_cleaning/train_X'

def load_images(X_images_dir,IMG_HEIGHT , IMG_WIDTH): 
  list_images = [] 
  for img in os.listdir(X_images_dir): 
    list_images.append(image.img_to_array(image.load_img(os.path.join(X_images_dir, img), target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='grayscale')))
  return np.array(list_images)

cur_time = time.time() 
yTrain_imag = load_images(X_images_dir, IMG_HEIGHT, IMG_WIDTH) 
print ('Время загрузки: ', round(time.time()-cur_time, 2), 'с', sep='')

yTrain_img = yTrain_imag/255

yTrain_img.shape

plt.imshow(yTrain_img[np.random.randint(0, yTrain_img.shape[0])].reshape(420, 540), cmap='gray') #выведем случайное изображение
plt.show()

test_dir = '/content/text_cleaning/text_cleaning/test'

def load_images(test_dir,IMG_HEIGHT , IMG_WIDTH): 
  list_images = [] 
  for img in os.listdir(test_dir): 
    list_images.append(image.img_to_array(image.load_img(os.path.join(test_dir, img), target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='grayscale')))
  return np.array(list_images)

cur_time = time.time() 
test_imag = load_images(test_dir, IMG_HEIGHT, IMG_WIDTH) 
print ('Время загрузки: ', round(time.time()-cur_time, 2), 'с', sep='')

test_img = test_imag/255

test_img.shape

plt.imshow(test_img[np.random.randint(0, test_img.shape[0])].reshape(420, 540), cmap='gray') 
plt.show()

def baseAutoencoder(shape=(IMG_HEIGHT,IMG_WIDTH,1)): 
    img_input = Input((shape)) 

    x = Conv2D(32, (3, 3), padding='same', activation='relu')(img_input) 
    x = BatchNormalization()(x) 
    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 
    x = MaxPooling2D()(x) 

    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 
    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)  
    x = BatchNormalization()(x) 
    z = MaxPooling2D()(x) 
    

    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', activation='relu')(z) 
    x = BatchNormalization()(x) 
    
    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 
    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 
    

    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 
    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 
    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x) 
    x = BatchNormalization()(x) 

    
    x = Conv2D(shape[-1], (3, 3), activation='sigmoid', padding='same')(x)

    model = Model(img_input, x) 
    model.compile(optimizer=Adam(lr=0.0001),
                  loss='mean_squared_error') 

    return model

modelCleaning = baseAutoencoder()

modelCleaning.summary()

history = modelCleaning.fit(yTrain_img[:47], xTrain_img[:47], epochs=150, batch_size=10, validation_data = (yTrain_img[47:], xTrain_img[47:]))

def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()

plot_graphs(history, 'loss')

modelCleaning.save_weights('modelCleaning.h5')

modelCleaning.load_weights('modelCleaning.h5')

def plotImages(xTrain, pred, shape=(420, 540)): 
  n = 5  
  plt.figure(figsize=(14, 7)) 
  for i in range(n): 
      index = np.random.randint(0, pred.shape[0]) 
      ax = plt.subplot(2, n, i + 1) 
      plt.imshow(xTrain[index].reshape(shape))    
      plt.gray() 
      ax.get_xaxis().set_visible(False) 
      ax.get_yaxis().set_visible(False) 

      
      ax = plt.subplot(2, n, i + 1 + n) 
      plt.imshow(pred[index].reshape(shape))    
      plt.gray() 
      ax.get_xaxis().set_visible(False) 
      ax.get_yaxis().set_visible(False) 
  plt.show()

predClean = modelCleaning.predict(yTrain_img[:40]) 
predClean = predClean * 255
predClean = predClean.astype('uint8')

plotImages(yTrain_img, predClean)

preds = modelCleaning.predict(test_img)

predClean_test = modelCleaning.predict(test_img[:40]) 
predClean_test = predClean_test * 255
predClean_test = predClean_test.astype('uint8')

plotImages(test_img, predClean_test)

def build_encoder():

    input_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1)) 
    
    
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)
    
    
    x = Conv2DTranspose(filters=32,kernel_size=3,strides=(2, 2),padding="same",activation='relu')(encoded)
    x = Conv2DTranspose(filters=32,kernel_size=3,strides=(2, 2),padding="same",activation='relu')(x)
    decoded = Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding="same", activation='sigmoid')(x)
    
    return Model(input_img, decoded)

autoencoder = build_encoder()

                              
autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])
autoencoder.summary()

history = autoencoder.fit(yTrain_img[:47], xTrain_img[:47], epochs=150, batch_size=10, validation_data = (yTrain_img[47:], xTrain_img[47:]))

plot_graphs(history, 'mse')

autoencoder.save_weights('automodel.h5')

autoencoder.load_weights('/content/automodel.h5')

preds = autoencoder.predict(test_img)

predAutoCl = autoencoder.predict(yTrain_img[:40]) 
predAutoCl = predAutoCl * 255 
predAutoCl = predAutoCl.astype('uint8')

plotImages(yTrain_img, predAutoCl)

predCL = autoencoder.predict(test_img[:40]) 
predCL = predCL * 255 
predCL = predCL.astype('uint8')

plotImages(test_img, predCL)